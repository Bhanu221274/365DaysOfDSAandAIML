Day 18 â€“ K-Nearest Neighbors (KNN) 

ðŸ”¹ What I Learned

- KNN is a simple algorithm that makes predictions based on the nearest data points.

- It uses distance metrics (like Euclidean) to find the closest neighbors.

- Classification â†’ majority vote of neighbors.

- Regression â†’ average of neighbors.

- Key parameters:

  - n_neighbors (K) â†’ number of neighbors considered.

  - metric â†’ distance calculation (default: Euclidean).

- Sensitive to scaling, so normalization/standardization helps.

ðŸ”¹ Implementation

- Dataset: Student Pass/Fail (based on Hours Studied & Assignments).

- Implemented KNeighborsClassifier from scikit-learn.

- Used K=3 for predictions.

- Evaluated using Accuracy Score and Confusion Matrix.

- Predicted outcome for a new studentâ€™s performance.
